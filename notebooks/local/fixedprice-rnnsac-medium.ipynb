{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, namedtuple\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import trange\n",
    "from copy import deepcopy\n",
    "\n",
    "# from dirichlet_actor_critic import Policy\n",
    "from env_two_step import Scenario, AMoD\n",
    "from util import mat2str, dictsum, moving_average\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Dirichlet\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "CPLEXPATH = \"/opt/ibm/ILOG/CPLEX_Studio128/opl/bin/x86-64_linux/\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, x_ext, x_temp, action, reward, next_x_ext, next_x_temp, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (x_ext, x_temp, action, reward, next_x_ext, next_x_temp, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        x_ext, x_temp, action, reward, next_x_ext, next_x_temp, done = map(np.stack, zip(*batch))\n",
    "        return x_ext, x_temp[:, 0], action, reward, next_x_ext, next_x_temp[:, 0], done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Dirichlet\n",
    "\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        # initialize affine transformations for neural net\n",
    "        self.affine1 = nn.Linear(56+16+1, 128)\n",
    "        self.affine2 = nn.Linear(128, 64)\n",
    "        self.affine3 = nn.Linear(64, 64)\n",
    "        \n",
    "        # initialize GRU cell\n",
    "        self.rnn = nn.GRU(input_size=56, hidden_size=32, batch_first=True)\n",
    "        self.h_0 = nn.Parameter(torch.zeros(1, 1, 32))\n",
    "        \n",
    "        # actor's layer\n",
    "        self.value_head = nn.Linear(96, 1)\n",
    "        \n",
    "    def forward(self, x_ext, x_temp):\n",
    "        x_ext = F.relu(self.affine1(x_ext))\n",
    "        x_ext = F.relu(self.affine2(x_ext))\n",
    "        x_ext = F.relu(self.affine3(x_ext))\n",
    "        \n",
    "        _, x_temp = self.rnn(x_temp, self.h_0.repeat(1, x_temp.size(0), 1))\n",
    "        \n",
    "        h = torch.cat((x_ext.view(-1, 64), x_temp.view(-1, 32)), dim=1)\n",
    "        x = self.value_head(h)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class SoftQNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoftQNetwork, self).__init__()\n",
    "        \n",
    "        # initialize affine transformations for neural net\n",
    "        self.affine1 = nn.Linear(56+16+1+8, 128)\n",
    "        self.affine2 = nn.Linear(128, 64)\n",
    "        self.affine3 = nn.Linear(64, 64)\n",
    "        \n",
    "        # initialize GRU cell\n",
    "        self.rnn = nn.GRU(input_size=56, hidden_size=32, batch_first=True)\n",
    "        self.h_0 = nn.Parameter(torch.zeros(1, 1, 32))\n",
    "        \n",
    "        # actor's layer\n",
    "        self.q_head = nn.Linear(96, 1)\n",
    "        \n",
    "    def forward(self, x_ext, x_temp, action):\n",
    "#         print(\"action: \", action.shape)\n",
    "        x_ext = torch.cat([x_ext, action.view(x_ext.size(0), 8)], 1)\n",
    "        x_ext = F.relu(self.affine1(x_ext))\n",
    "        x_ext = F.relu(self.affine2(x_ext))\n",
    "        x_ext = F.relu(self.affine3(x_ext))\n",
    "        \n",
    "        _, x_temp = self.rnn(x_temp, self.h_0.repeat(1, x_temp.size(0), 1))\n",
    "        \n",
    "        h = torch.cat((x_ext.view(-1, 64), x_temp.view(-1, 32)), dim=1)\n",
    "        x = self.q_head(h)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.env = env\n",
    "        # initialize affine transformations for neural net\n",
    "        self.affine1 = nn.Linear(56+16+1, 128)\n",
    "        self.affine2 = nn.Linear(128, 64)\n",
    "        self.affine3 = nn.Linear(64, 64)\n",
    "        \n",
    "        # initialize GRU cell\n",
    "        self.rnn = nn.GRU(input_size=56, hidden_size=32, batch_first=True)\n",
    "        self.h_0 = nn.Parameter(torch.zeros(1, 1, 32))\n",
    "        \n",
    "        # actor's layer\n",
    "        self.action_head = nn.Linear(96, 8)\n",
    "        \n",
    "    def forward(self, x_ext, x_temp):\n",
    "        \"\"\"\n",
    "        forward of both actor and critic\n",
    "        \"\"\"\n",
    "        x_ext = F.relu(self.affine1(x_ext))\n",
    "        x_ext = F.relu(self.affine2(x_ext))\n",
    "        x_ext = F.relu(self.affine3(x_ext))\n",
    "        \n",
    "#         print(x_temp.shape)\n",
    "        _, x_temp = self.rnn(x_temp, self.h_0.repeat(1, x_temp.size(0), 1))\n",
    "        \n",
    "        h = torch.cat((x_ext.view(-1, 64), x_temp.view(-1, 32)), dim=1)\n",
    "        \n",
    "        # actor: choses action to take from state s_t \n",
    "        # by returning probability of each action\n",
    "        action_prob = F.softplus(self.action_head(h)).reshape(-1, 8) + 1e-20\n",
    "        \n",
    "        return action_prob\n",
    "    \n",
    "    def evaluate(self, x_ext, x_temp, epsilon=1e-6):\n",
    "        concentrations = self.forward(x_ext, x_temp)\n",
    "        print(concentrations.shape)\n",
    "        m = Dirichlet(concentrations)\n",
    "\n",
    "        # and sample an action using the distribution\n",
    "        action = m.sample() + 1e-20\n",
    "        \n",
    "        log_prob = m.log_prob(action) #- torch.log(1 - action.pow(2) + epsilon)\n",
    "        log_prob = log_prob.view(-1,1)#.sum(-1, keepdim=True)\n",
    "        \n",
    "        return action, log_prob, concentrations\n",
    "        \n",
    "    \n",
    "    def get_action(self, state):\n",
    "        concentrations = self.forward(state[0], state[1])\n",
    "        \n",
    "        m = Dirichlet(concentrations)\n",
    "\n",
    "        # and sample an action using the distribution\n",
    "        action = m.sample()\n",
    "        return list(action[0].numpy())\n",
    "    \n",
    "    def get_available_vehicles(self):\n",
    "        \"\"\"\n",
    "        Count total number of available vehicles.\n",
    "        \"\"\"\n",
    "        return np.sum([self.env.acc[region][self.env.time] for region in self.env.region])\n",
    "    \n",
    "    def get_desired_distribution(self, action_rl):\n",
    "        \"\"\"\n",
    "        Given a RL action, returns the desired number of vehicles in each area.\n",
    "        \"\"\"\n",
    "        v_d = action_rl*self.get_available_vehicles()\n",
    "        return list(v_d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_q_update(batch_size, \n",
    "           gamma=0.99,\n",
    "           concentrations_lambda=1e-3,\n",
    "           soft_tau=1e-2,\n",
    "          ):\n",
    "    x_ext, x_temp, action, reward, next_x_ext, next_x_temp, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    x_ext      = torch.FloatTensor(x_ext).to(device)\n",
    "    x_temp      = torch.FloatTensor(x_temp).to(device)\n",
    "    next_x_ext = torch.FloatTensor(next_x_ext).to(device)\n",
    "    next_x_temp = torch.FloatTensor(next_x_temp).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "    \n",
    "    expected_q_value1 = soft_q_net1(x_ext, x_temp, action)\n",
    "    expected_q_value2 = soft_q_net2(x_ext, x_temp, action)\n",
    "    expected_q_value = torch.min(expected_q_value1, expected_q_value2)\n",
    "    print(f\"Expected q value: {expected_q_value.mean()}, {expected_q_value.shape}\")\n",
    "    expected_value   = value_net(x_ext, x_temp)\n",
    "    new_action, log_prob, concentrations = policy_net.evaluate(x_ext, x_temp)\n",
    "\n",
    "    target_value = target_value_net(next_x_ext, next_x_temp)\n",
    "    print(f\"Target value: {target_value.mean()}, {target_value.shape}\")\n",
    "    next_q_value = reward + (1 - done) * gamma * (target_value)\n",
    "    q_value_loss = soft_q_criterion(expected_q_value, next_q_value.detach())\n",
    "\n",
    "    expected_new_q_value1 = soft_q_net1(x_ext, x_temp, new_action)\n",
    "    expected_new_q_value2 = soft_q_net2(x_ext, x_temp, new_action)\n",
    "    expected_new_q_value = torch.min(expected_new_q_value1, expected_new_q_value2)\n",
    "    print(f\"Expected new q: {expected_new_q_value.mean()}, {expected_new_q_value.shape}\")\n",
    "    next_value = expected_new_q_value - 0.1*log_prob\n",
    "    value_loss = value_criterion(expected_value, next_value.detach())\n",
    "\n",
    "    log_prob_target = expected_new_q_value - expected_value\n",
    "    print(f\"Log prob: {log_prob.mean()}, {log_prob.shape}\")\n",
    "#     policy_loss = (0.2*log_prob - expected_new_q_value).mean()\n",
    "    policy_loss = (0.1*log_prob * (log_prob - log_prob_target).detach()).mean()\n",
    "    \n",
    "\n",
    "    concentrations_loss = concentrations_lambda * concentrations.pow(2).sum(1).mean()\n",
    "\n",
    "    policy_loss += concentrations_loss\n",
    "\n",
    "    soft_q_optimizer1.zero_grad()\n",
    "    soft_q_optimizer2.zero_grad()\n",
    "    q_value_loss.backward()\n",
    "    soft_q_optimizer1.step()\n",
    "    soft_q_optimizer2.step()\n",
    "\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "\n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    \n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build scenario\n",
    "scenario = Scenario(sd=10,demand_input = {(1,6):2, (0,7):2, 'default':0.1}, fix_price=True)\n",
    "env = AMoD(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_net        = ValueNetwork().to(device)\n",
    "target_value_net = ValueNetwork().to(device)\n",
    "\n",
    "soft_q_net1 = SoftQNetwork().to(device)\n",
    "soft_q_net2 = SoftQNetwork().to(device)\n",
    "policy_net = PolicyNetwork(env).to(device)\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "    \n",
    "\n",
    "value_criterion  = nn.MSELoss()\n",
    "soft_q_criterion = nn.MSELoss()\n",
    "\n",
    "value_lr  = 3e-4\n",
    "soft_q_lr = 3e-4\n",
    "policy_lr = 3e-4\n",
    "\n",
    "value_optimizer  = optim.Adam(value_net.parameters(), lr=value_lr)\n",
    "soft_q_optimizer1 = optim.Adam(soft_q_net1.parameters(), lr=soft_q_lr)\n",
    "soft_q_optimizer2 = optim.Adam(soft_q_net2.parameters(), lr=soft_q_lr)\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "\n",
    "\n",
    "replay_buffer_size = 1000000\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames  = 40000\n",
    "max_steps   = 500\n",
    "frame_idx   = 0\n",
    "rewards     = []\n",
    "batch_size  = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 1251 | Reward: 2769.40 | Revenue: 3069.00 | ServedDemand: 354.00 | Reb. Cost: 95.00 | Oper. Cost: 299.60:   3%|▎         | 1251/50000 [12:11:04<420:40:04, 31.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected q value: 1140.671630859375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1106.851806640625, torch.Size([256, 1])\n",
      "Expected new q: 1141.0377197265625, torch.Size([256, 1])\n",
      "Log prob: 10.867460250854492, torch.Size([256, 1])\n",
      "Expected q value: 1117.5914306640625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1080.40478515625, torch.Size([256, 1])\n",
      "Expected new q: 1117.931884765625, torch.Size([256, 1])\n",
      "Log prob: 10.877243041992188, torch.Size([256, 1])\n",
      "Expected q value: 1058.0504150390625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1027.1337890625, torch.Size([256, 1])\n",
      "Expected new q: 1058.2957763671875, torch.Size([256, 1])\n",
      "Log prob: 10.893722534179688, torch.Size([256, 1])\n",
      "Expected q value: 1101.0631103515625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1069.62841796875, torch.Size([256, 1])\n",
      "Expected new q: 1101.31298828125, torch.Size([256, 1])\n",
      "Log prob: 10.798723220825195, torch.Size([256, 1])\n",
      "Expected q value: 1165.551025390625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1131.5966796875, torch.Size([256, 1])\n",
      "Expected new q: 1165.54931640625, torch.Size([256, 1])\n",
      "Log prob: 10.802497863769531, torch.Size([256, 1])\n",
      "Expected q value: 1106.7081298828125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1066.0128173828125, torch.Size([256, 1])\n",
      "Expected new q: 1106.85986328125, torch.Size([256, 1])\n",
      "Log prob: 10.878962516784668, torch.Size([256, 1])\n",
      "Expected q value: 1051.9234619140625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1017.1612548828125, torch.Size([256, 1])\n",
      "Expected new q: 1052.3359375, torch.Size([256, 1])\n",
      "Log prob: 11.11027717590332, torch.Size([256, 1])\n",
      "Expected q value: 1171.95703125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1143.424560546875, torch.Size([256, 1])\n",
      "Expected new q: 1172.5574951171875, torch.Size([256, 1])\n",
      "Log prob: 11.093101501464844, torch.Size([256, 1])\n",
      "Expected q value: 1092.9053955078125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1064.9442138671875, torch.Size([256, 1])\n",
      "Expected new q: 1093.22802734375, torch.Size([256, 1])\n",
      "Log prob: 11.105127334594727, torch.Size([256, 1])\n",
      "Expected q value: 1076.6639404296875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1041.1536865234375, torch.Size([256, 1])\n",
      "Expected new q: 1077.2119140625, torch.Size([256, 1])\n",
      "Log prob: 10.912542343139648, torch.Size([256, 1])\n",
      "Expected q value: 1131.8179931640625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1093.98388671875, torch.Size([256, 1])\n",
      "Expected new q: 1132.242431640625, torch.Size([256, 1])\n",
      "Log prob: 10.807792663574219, torch.Size([256, 1])\n",
      "Expected q value: 1032.1978759765625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 994.4136352539062, torch.Size([256, 1])\n",
      "Expected new q: 1032.738037109375, torch.Size([256, 1])\n",
      "Log prob: 11.108261108398438, torch.Size([256, 1])\n",
      "Expected q value: 1127.421875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1097.3621826171875, torch.Size([256, 1])\n",
      "Expected new q: 1127.6146240234375, torch.Size([256, 1])\n",
      "Log prob: 10.698850631713867, torch.Size([256, 1])\n",
      "Expected q value: 1104.0062255859375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1076.781982421875, torch.Size([256, 1])\n",
      "Expected new q: 1104.2294921875, torch.Size([256, 1])\n",
      "Log prob: 10.887359619140625, torch.Size([256, 1])\n",
      "Expected q value: 1093.66552734375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1057.9072265625, torch.Size([256, 1])\n",
      "Expected new q: 1094.2054443359375, torch.Size([256, 1])\n",
      "Log prob: 10.910404205322266, torch.Size([256, 1])\n",
      "Expected q value: 1092.265625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1055.25244140625, torch.Size([256, 1])\n",
      "Expected new q: 1092.75732421875, torch.Size([256, 1])\n",
      "Log prob: 11.00083065032959, torch.Size([256, 1])\n",
      "Expected q value: 1100.527099609375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1065.3486328125, torch.Size([256, 1])\n",
      "Expected new q: 1100.89501953125, torch.Size([256, 1])\n",
      "Log prob: 10.943087577819824, torch.Size([256, 1])\n",
      "Expected q value: 1067.6376953125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1034.667236328125, torch.Size([256, 1])\n",
      "Expected new q: 1067.48876953125, torch.Size([256, 1])\n",
      "Log prob: 10.876653671264648, torch.Size([256, 1])\n",
      "Expected q value: 1106.9381103515625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1075.4219970703125, torch.Size([256, 1])\n",
      "Expected new q: 1107.1898193359375, torch.Size([256, 1])\n",
      "Log prob: 10.936368942260742, torch.Size([256, 1])\n",
      "Expected q value: 1145.4022216796875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1115.0498046875, torch.Size([256, 1])\n",
      "Expected new q: 1145.8489990234375, torch.Size([256, 1])\n",
      "Log prob: 11.062253952026367, torch.Size([256, 1])\n",
      "Expected q value: 1113.0985107421875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1075.5855712890625, torch.Size([256, 1])\n",
      "Expected new q: 1113.1676025390625, torch.Size([256, 1])\n",
      "Log prob: 10.904951095581055, torch.Size([256, 1])\n",
      "Expected q value: 1122.40673828125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1085.45556640625, torch.Size([256, 1])\n",
      "Expected new q: 1122.6251220703125, torch.Size([256, 1])\n",
      "Log prob: 10.70631217956543, torch.Size([256, 1])\n",
      "Expected q value: 1127.6424560546875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1093.9581298828125, torch.Size([256, 1])\n",
      "Expected new q: 1127.7119140625, torch.Size([256, 1])\n",
      "Log prob: 10.830209732055664, torch.Size([256, 1])\n",
      "Expected q value: 1083.0111083984375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1054.3756103515625, torch.Size([256, 1])\n",
      "Expected new q: 1083.64453125, torch.Size([256, 1])\n",
      "Log prob: 10.978055000305176, torch.Size([256, 1])\n",
      "Expected q value: 1084.009521484375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1050.8389892578125, torch.Size([256, 1])\n",
      "Expected new q: 1084.093505859375, torch.Size([256, 1])\n",
      "Log prob: 10.718071937561035, torch.Size([256, 1])\n",
      "Expected q value: 1122.022705078125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1083.8123779296875, torch.Size([256, 1])\n",
      "Expected new q: 1122.337646484375, torch.Size([256, 1])\n",
      "Log prob: 10.861477851867676, torch.Size([256, 1])\n",
      "Expected q value: 1097.93994140625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1060.2939453125, torch.Size([256, 1])\n",
      "Expected new q: 1098.080810546875, torch.Size([256, 1])\n",
      "Log prob: 10.748571395874023, torch.Size([256, 1])\n",
      "Expected q value: 1092.90771484375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1065.0576171875, torch.Size([256, 1])\n",
      "Expected new q: 1093.443603515625, torch.Size([256, 1])\n",
      "Log prob: 11.011202812194824, torch.Size([256, 1])\n",
      "Expected q value: 1118.606201171875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1092.3375244140625, torch.Size([256, 1])\n",
      "Expected new q: 1118.8358154296875, torch.Size([256, 1])\n",
      "Log prob: 10.76370620727539, torch.Size([256, 1])\n",
      "Expected q value: 1052.039794921875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1014.9174194335938, torch.Size([256, 1])\n",
      "Expected new q: 1052.3651123046875, torch.Size([256, 1])\n",
      "Log prob: 10.878408432006836, torch.Size([256, 1])\n",
      "Expected q value: 1124.965576171875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1085.3001708984375, torch.Size([256, 1])\n",
      "Expected new q: 1125.1669921875, torch.Size([256, 1])\n",
      "Log prob: 10.846693992614746, torch.Size([256, 1])\n",
      "Expected q value: 1060.5626220703125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1024.577880859375, torch.Size([256, 1])\n",
      "Expected new q: 1060.78173828125, torch.Size([256, 1])\n",
      "Log prob: 10.8555269241333, torch.Size([256, 1])\n",
      "Expected q value: 1067.1107177734375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1037.70361328125, torch.Size([256, 1])\n",
      "Expected new q: 1067.1385498046875, torch.Size([256, 1])\n",
      "Log prob: 10.897995948791504, torch.Size([256, 1])\n",
      "Expected q value: 1086.719482421875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1055.2744140625, torch.Size([256, 1])\n",
      "Expected new q: 1087.2164306640625, torch.Size([256, 1])\n",
      "Log prob: 10.959493637084961, torch.Size([256, 1])\n",
      "Expected q value: 1077.0537109375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1042.465576171875, torch.Size([256, 1])\n",
      "Expected new q: 1077.16845703125, torch.Size([256, 1])\n",
      "Log prob: 10.821552276611328, torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected q value: 1108.916015625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1071.323974609375, torch.Size([256, 1])\n",
      "Expected new q: 1109.026123046875, torch.Size([256, 1])\n",
      "Log prob: 10.801746368408203, torch.Size([256, 1])\n",
      "Expected q value: 1067.491943359375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1031.793212890625, torch.Size([256, 1])\n",
      "Expected new q: 1068.0184326171875, torch.Size([256, 1])\n",
      "Log prob: 10.956714630126953, torch.Size([256, 1])\n",
      "Expected q value: 1137.168701171875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1111.154296875, torch.Size([256, 1])\n",
      "Expected new q: 1137.2593994140625, torch.Size([256, 1])\n",
      "Log prob: 10.786877632141113, torch.Size([256, 1])\n",
      "Expected q value: 1062.326904296875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1030.9248046875, torch.Size([256, 1])\n",
      "Expected new q: 1062.6363525390625, torch.Size([256, 1])\n",
      "Log prob: 10.870406150817871, torch.Size([256, 1])\n",
      "Expected q value: 1079.09521484375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1045.8670654296875, torch.Size([256, 1])\n",
      "Expected new q: 1079.46728515625, torch.Size([256, 1])\n",
      "Log prob: 10.804925918579102, torch.Size([256, 1])\n",
      "Expected q value: 1157.01513671875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1121.28369140625, torch.Size([256, 1])\n",
      "Expected new q: 1157.232421875, torch.Size([256, 1])\n",
      "Log prob: 10.880447387695312, torch.Size([256, 1])\n",
      "Expected q value: 1104.342041015625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1067.662353515625, torch.Size([256, 1])\n",
      "Expected new q: 1104.33056640625, torch.Size([256, 1])\n",
      "Log prob: 10.450420379638672, torch.Size([256, 1])\n",
      "Expected q value: 1166.771728515625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1136.0919189453125, torch.Size([256, 1])\n",
      "Expected new q: 1166.459228515625, torch.Size([256, 1])\n",
      "Log prob: 10.440457344055176, torch.Size([256, 1])\n",
      "Expected q value: 1079.5355224609375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1044.3701171875, torch.Size([256, 1])\n",
      "Expected new q: 1079.9959716796875, torch.Size([256, 1])\n",
      "Log prob: 10.833328247070312, torch.Size([256, 1])\n",
      "Expected q value: 1096.3310546875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1060.2713623046875, torch.Size([256, 1])\n",
      "Expected new q: 1096.599853515625, torch.Size([256, 1])\n",
      "Log prob: 10.513337135314941, torch.Size([256, 1])\n",
      "Expected q value: 1082.96142578125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1045.868408203125, torch.Size([256, 1])\n",
      "Expected new q: 1082.8065185546875, torch.Size([256, 1])\n",
      "Log prob: 10.61271858215332, torch.Size([256, 1])\n",
      "Expected q value: 1101.1422119140625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1070.42919921875, torch.Size([256, 1])\n",
      "Expected new q: 1100.9990234375, torch.Size([256, 1])\n",
      "Log prob: 10.564913749694824, torch.Size([256, 1])\n",
      "Expected q value: 1145.9267578125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1114.4420166015625, torch.Size([256, 1])\n",
      "Expected new q: 1146.0357666015625, torch.Size([256, 1])\n",
      "Log prob: 10.593071937561035, torch.Size([256, 1])\n",
      "Expected q value: 1032.7069091796875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1000.0833740234375, torch.Size([256, 1])\n",
      "Expected new q: 1032.728271484375, torch.Size([256, 1])\n",
      "Log prob: 10.769311904907227, torch.Size([256, 1])\n",
      "Expected q value: 1075.0128173828125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1040.0885009765625, torch.Size([256, 1])\n",
      "Expected new q: 1074.9945068359375, torch.Size([256, 1])\n",
      "Log prob: 10.665722846984863, torch.Size([256, 1])\n",
      "Expected q value: 1036.76611328125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 999.7911987304688, torch.Size([256, 1])\n",
      "Expected new q: 1036.837646484375, torch.Size([256, 1])\n",
      "Log prob: 10.70166301727295, torch.Size([256, 1])\n",
      "Expected q value: 1036.015380859375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1004.2196655273438, torch.Size([256, 1])\n",
      "Expected new q: 1035.7860107421875, torch.Size([256, 1])\n",
      "Log prob: 10.675750732421875, torch.Size([256, 1])\n",
      "Expected q value: 1113.15771484375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1082.759521484375, torch.Size([256, 1])\n",
      "Expected new q: 1113.0933837890625, torch.Size([256, 1])\n",
      "Log prob: 10.522579193115234, torch.Size([256, 1])\n",
      "Expected q value: 1095.1981201171875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1061.3294677734375, torch.Size([256, 1])\n",
      "Expected new q: 1095.128173828125, torch.Size([256, 1])\n",
      "Log prob: 10.721099853515625, torch.Size([256, 1])\n",
      "Expected q value: 1099.77685546875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1062.895263671875, torch.Size([256, 1])\n",
      "Expected new q: 1099.5518798828125, torch.Size([256, 1])\n",
      "Log prob: 10.693967819213867, torch.Size([256, 1])\n",
      "Expected q value: 1170.59033203125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1136.747802734375, torch.Size([256, 1])\n",
      "Expected new q: 1170.7064208984375, torch.Size([256, 1])\n",
      "Log prob: 10.841145515441895, torch.Size([256, 1])\n",
      "Expected q value: 1129.123779296875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1098.2850341796875, torch.Size([256, 1])\n",
      "Expected new q: 1129.0635986328125, torch.Size([256, 1])\n",
      "Log prob: 10.731583595275879, torch.Size([256, 1])\n",
      "Expected q value: 1104.4207763671875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1069.8697509765625, torch.Size([256, 1])\n",
      "Expected new q: 1104.333740234375, torch.Size([256, 1])\n",
      "Log prob: 10.581534385681152, torch.Size([256, 1])\n",
      "Expected q value: 1050.4151611328125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1016.6362915039062, torch.Size([256, 1])\n",
      "Expected new q: 1050.3404541015625, torch.Size([256, 1])\n",
      "Log prob: 10.71536636352539, torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1252 | Reward: 2677.40 | Revenue: 2979.00 | ServedDemand: 331.00 | Reb. Cost: 103.00 | Oper. Cost: 301.60:   3%|▎         | 1252/50000 [12:11:35<421:31:55, 31.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected q value: 1062.65185546875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1028.5604248046875, torch.Size([256, 1])\n",
      "Expected new q: 1062.7760009765625, torch.Size([256, 1])\n",
      "Log prob: 10.615538597106934, torch.Size([256, 1])\n",
      "Expected q value: 1126.522216796875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1092.67578125, torch.Size([256, 1])\n",
      "Expected new q: 1126.715087890625, torch.Size([256, 1])\n",
      "Log prob: 10.81954574584961, torch.Size([256, 1])\n",
      "Expected q value: 1051.766357421875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1022.0250244140625, torch.Size([256, 1])\n",
      "Expected new q: 1051.9534912109375, torch.Size([256, 1])\n",
      "Log prob: 10.788832664489746, torch.Size([256, 1])\n",
      "Expected q value: 1129.7679443359375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1094.935791015625, torch.Size([256, 1])\n",
      "Expected new q: 1129.9197998046875, torch.Size([256, 1])\n",
      "Log prob: 10.919925689697266, torch.Size([256, 1])\n",
      "Expected q value: 1045.28271484375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1007.6644897460938, torch.Size([256, 1])\n",
      "Expected new q: 1045.5947265625, torch.Size([256, 1])\n",
      "Log prob: 10.813249588012695, torch.Size([256, 1])\n",
      "Expected q value: 1171.914794921875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1139.298095703125, torch.Size([256, 1])\n",
      "Expected new q: 1172.1593017578125, torch.Size([256, 1])\n",
      "Log prob: 10.915241241455078, torch.Size([256, 1])\n",
      "Expected q value: 1098.2733154296875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1065.836181640625, torch.Size([256, 1])\n",
      "Expected new q: 1098.669189453125, torch.Size([256, 1])\n",
      "Log prob: 10.855966567993164, torch.Size([256, 1])\n",
      "Expected q value: 1088.378173828125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1054.1263427734375, torch.Size([256, 1])\n",
      "Expected new q: 1088.3902587890625, torch.Size([256, 1])\n",
      "Log prob: 10.779268264770508, torch.Size([256, 1])\n",
      "Expected q value: 1024.013916015625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 991.0257568359375, torch.Size([256, 1])\n",
      "Expected new q: 1024.574951171875, torch.Size([256, 1])\n",
      "Log prob: 10.853377342224121, torch.Size([256, 1])\n",
      "Expected q value: 1113.5848388671875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1081.1195068359375, torch.Size([256, 1])\n",
      "Expected new q: 1113.556396484375, torch.Size([256, 1])\n",
      "Log prob: 10.76800537109375, torch.Size([256, 1])\n",
      "Expected q value: 1082.7607421875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1046.29638671875, torch.Size([256, 1])\n",
      "Expected new q: 1082.871826171875, torch.Size([256, 1])\n",
      "Log prob: 10.746662139892578, torch.Size([256, 1])\n",
      "Expected q value: 1078.8436279296875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1044.3060302734375, torch.Size([256, 1])\n",
      "Expected new q: 1079.339111328125, torch.Size([256, 1])\n",
      "Log prob: 11.034314155578613, torch.Size([256, 1])\n",
      "Expected q value: 1051.962158203125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1021.74609375, torch.Size([256, 1])\n",
      "Expected new q: 1052.1878662109375, torch.Size([256, 1])\n",
      "Log prob: 10.633386611938477, torch.Size([256, 1])\n",
      "Expected q value: 1113.8201904296875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1083.614013671875, torch.Size([256, 1])\n",
      "Expected new q: 1114.111572265625, torch.Size([256, 1])\n",
      "Log prob: 10.839062690734863, torch.Size([256, 1])\n",
      "Expected q value: 1086.879638671875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1052.8382568359375, torch.Size([256, 1])\n",
      "Expected new q: 1087.13671875, torch.Size([256, 1])\n",
      "Log prob: 10.806705474853516, torch.Size([256, 1])\n",
      "Expected q value: 1092.444580078125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1058.7142333984375, torch.Size([256, 1])\n",
      "Expected new q: 1092.4052734375, torch.Size([256, 1])\n",
      "Log prob: 10.620994567871094, torch.Size([256, 1])\n",
      "Expected q value: 1116.5584716796875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1081.188720703125, torch.Size([256, 1])\n",
      "Expected new q: 1117.189208984375, torch.Size([256, 1])\n",
      "Log prob: 10.879142761230469, torch.Size([256, 1])\n",
      "Expected q value: 1131.0142822265625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1099.6175537109375, torch.Size([256, 1])\n",
      "Expected new q: 1131.30615234375, torch.Size([256, 1])\n",
      "Log prob: 10.868522644042969, torch.Size([256, 1])\n",
      "Expected q value: 1112.7156982421875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1078.06201171875, torch.Size([256, 1])\n",
      "Expected new q: 1112.8096923828125, torch.Size([256, 1])\n",
      "Log prob: 10.845059394836426, torch.Size([256, 1])\n",
      "Expected q value: 1078.427001953125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1045.43017578125, torch.Size([256, 1])\n",
      "Expected new q: 1078.5306396484375, torch.Size([256, 1])\n",
      "Log prob: 10.69933032989502, torch.Size([256, 1])\n",
      "Expected q value: 1157.1856689453125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1121.893310546875, torch.Size([256, 1])\n",
      "Expected new q: 1157.1689453125, torch.Size([256, 1])\n",
      "Log prob: 10.752470016479492, torch.Size([256, 1])\n",
      "Expected q value: 1121.09423828125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1090.6802978515625, torch.Size([256, 1])\n",
      "Expected new q: 1121.38525390625, torch.Size([256, 1])\n",
      "Log prob: 10.688348770141602, torch.Size([256, 1])\n",
      "Expected q value: 1104.9285888671875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1070.84130859375, torch.Size([256, 1])\n",
      "Expected new q: 1104.6649169921875, torch.Size([256, 1])\n",
      "Log prob: 10.589628219604492, torch.Size([256, 1])\n",
      "Expected q value: 1122.81201171875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1087.9862060546875, torch.Size([256, 1])\n",
      "Expected new q: 1123.1903076171875, torch.Size([256, 1])\n",
      "Log prob: 11.052240371704102, torch.Size([256, 1])\n",
      "Expected q value: 1064.50732421875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1029.4505615234375, torch.Size([256, 1])\n",
      "Expected new q: 1064.8778076171875, torch.Size([256, 1])\n",
      "Log prob: 10.731033325195312, torch.Size([256, 1])\n",
      "Expected q value: 1076.154541015625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1042.865966796875, torch.Size([256, 1])\n",
      "Expected new q: 1076.73291015625, torch.Size([256, 1])\n",
      "Log prob: 10.864054679870605, torch.Size([256, 1])\n",
      "Expected q value: 1078.3555908203125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1044.6390380859375, torch.Size([256, 1])\n",
      "Expected new q: 1078.8629150390625, torch.Size([256, 1])\n",
      "Log prob: 11.027740478515625, torch.Size([256, 1])\n",
      "Expected q value: 1057.614013671875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1023.3893432617188, torch.Size([256, 1])\n",
      "Expected new q: 1058.3917236328125, torch.Size([256, 1])\n",
      "Log prob: 11.132366180419922, torch.Size([256, 1])\n",
      "Expected q value: 1198.01318359375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1167.7274169921875, torch.Size([256, 1])\n",
      "Expected new q: 1198.2879638671875, torch.Size([256, 1])\n",
      "Log prob: 10.749862670898438, torch.Size([256, 1])\n",
      "Expected q value: 1124.6231689453125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1093.120361328125, torch.Size([256, 1])\n",
      "Expected new q: 1125.0870361328125, torch.Size([256, 1])\n",
      "Log prob: 10.992300987243652, torch.Size([256, 1])\n",
      "Expected q value: 1073.01904296875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1037.7286376953125, torch.Size([256, 1])\n",
      "Expected new q: 1073.475830078125, torch.Size([256, 1])\n",
      "Log prob: 10.89523983001709, torch.Size([256, 1])\n",
      "Expected q value: 1114.75390625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1079.382568359375, torch.Size([256, 1])\n",
      "Expected new q: 1114.9144287109375, torch.Size([256, 1])\n",
      "Log prob: 10.938652038574219, torch.Size([256, 1])\n",
      "Expected q value: 1074.8321533203125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1045.6591796875, torch.Size([256, 1])\n",
      "Expected new q: 1074.708251953125, torch.Size([256, 1])\n",
      "Log prob: 10.757808685302734, torch.Size([256, 1])\n",
      "Expected q value: 1068.3944091796875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1035.2213134765625, torch.Size([256, 1])\n",
      "Expected new q: 1068.7481689453125, torch.Size([256, 1])\n",
      "Log prob: 11.032247543334961, torch.Size([256, 1])\n",
      "Expected q value: 1134.880859375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1097.9326171875, torch.Size([256, 1])\n",
      "Expected new q: 1135.0115966796875, torch.Size([256, 1])\n",
      "Log prob: 10.81070327758789, torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected q value: 1116.05810546875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1078.2763671875, torch.Size([256, 1])\n",
      "Expected new q: 1116.5604248046875, torch.Size([256, 1])\n",
      "Log prob: 10.95545768737793, torch.Size([256, 1])\n",
      "Expected q value: 1062.230712890625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1031.021484375, torch.Size([256, 1])\n",
      "Expected new q: 1062.98291015625, torch.Size([256, 1])\n",
      "Log prob: 11.178716659545898, torch.Size([256, 1])\n",
      "Expected q value: 1116.844970703125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1089.5338134765625, torch.Size([256, 1])\n",
      "Expected new q: 1117.3450927734375, torch.Size([256, 1])\n",
      "Log prob: 10.923730850219727, torch.Size([256, 1])\n",
      "Expected q value: 1098.092529296875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1067.114990234375, torch.Size([256, 1])\n",
      "Expected new q: 1098.1016845703125, torch.Size([256, 1])\n",
      "Log prob: 10.832681655883789, torch.Size([256, 1])\n",
      "Expected q value: 1132.280517578125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1091.907470703125, torch.Size([256, 1])\n",
      "Expected new q: 1132.4410400390625, torch.Size([256, 1])\n",
      "Log prob: 10.892579078674316, torch.Size([256, 1])\n",
      "Expected q value: 1098.104736328125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1062.831787109375, torch.Size([256, 1])\n",
      "Expected new q: 1098.32568359375, torch.Size([256, 1])\n",
      "Log prob: 10.91779899597168, torch.Size([256, 1])\n",
      "Expected q value: 1162.4429931640625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1134.9127197265625, torch.Size([256, 1])\n",
      "Expected new q: 1162.49267578125, torch.Size([256, 1])\n",
      "Log prob: 10.894062042236328, torch.Size([256, 1])\n",
      "Expected q value: 1090.0531005859375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1059.360107421875, torch.Size([256, 1])\n",
      "Expected new q: 1090.7044677734375, torch.Size([256, 1])\n",
      "Log prob: 11.082204818725586, torch.Size([256, 1])\n",
      "Expected q value: 1069.77197265625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1033.423095703125, torch.Size([256, 1])\n",
      "Expected new q: 1069.88232421875, torch.Size([256, 1])\n",
      "Log prob: 10.78357219696045, torch.Size([256, 1])\n",
      "Expected q value: 1122.920654296875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1082.10302734375, torch.Size([256, 1])\n",
      "Expected new q: 1123.17333984375, torch.Size([256, 1])\n",
      "Log prob: 10.703957557678223, torch.Size([256, 1])\n",
      "Expected q value: 1091.739013671875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1057.2720947265625, torch.Size([256, 1])\n",
      "Expected new q: 1092.0123291015625, torch.Size([256, 1])\n",
      "Log prob: 10.91385269165039, torch.Size([256, 1])\n",
      "Expected q value: 1101.1793212890625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1072.2379150390625, torch.Size([256, 1])\n",
      "Expected new q: 1101.298828125, torch.Size([256, 1])\n",
      "Log prob: 10.7891845703125, torch.Size([256, 1])\n",
      "Expected q value: 1144.970947265625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1117.9697265625, torch.Size([256, 1])\n",
      "Expected new q: 1145.28076171875, torch.Size([256, 1])\n",
      "Log prob: 10.902605056762695, torch.Size([256, 1])\n",
      "Expected q value: 1104.0286865234375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1067.032470703125, torch.Size([256, 1])\n",
      "Expected new q: 1104.6221923828125, torch.Size([256, 1])\n",
      "Log prob: 11.014265060424805, torch.Size([256, 1])\n",
      "Expected q value: 1112.3597412109375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1072.501953125, torch.Size([256, 1])\n",
      "Expected new q: 1113.0013427734375, torch.Size([256, 1])\n",
      "Log prob: 10.919146537780762, torch.Size([256, 1])\n",
      "Expected q value: 1123.7506103515625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1092.30859375, torch.Size([256, 1])\n",
      "Expected new q: 1124.357666015625, torch.Size([256, 1])\n",
      "Log prob: 11.054182052612305, torch.Size([256, 1])\n",
      "Expected q value: 1178.4610595703125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1147.9541015625, torch.Size([256, 1])\n",
      "Expected new q: 1178.884765625, torch.Size([256, 1])\n",
      "Log prob: 11.076361656188965, torch.Size([256, 1])\n",
      "Expected q value: 1098.6663818359375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1064.7547607421875, torch.Size([256, 1])\n",
      "Expected new q: 1098.9644775390625, torch.Size([256, 1])\n",
      "Log prob: 11.044133186340332, torch.Size([256, 1])\n",
      "Expected q value: 1061.8673095703125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1025.5086669921875, torch.Size([256, 1])\n",
      "Expected new q: 1062.34765625, torch.Size([256, 1])\n",
      "Log prob: 10.988149642944336, torch.Size([256, 1])\n",
      "Expected q value: 1104.322021484375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1070.22900390625, torch.Size([256, 1])\n",
      "Expected new q: 1104.8236083984375, torch.Size([256, 1])\n",
      "Log prob: 11.050275802612305, torch.Size([256, 1])\n",
      "Expected q value: 1128.091552734375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1092.9512939453125, torch.Size([256, 1])\n",
      "Expected new q: 1128.463623046875, torch.Size([256, 1])\n",
      "Log prob: 11.017258644104004, torch.Size([256, 1])\n",
      "Expected q value: 1123.388427734375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1090.5631103515625, torch.Size([256, 1])\n",
      "Expected new q: 1123.908935546875, torch.Size([256, 1])\n",
      "Log prob: 10.975467681884766, torch.Size([256, 1])\n",
      "Expected q value: 1090.4747314453125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1060.806640625, torch.Size([256, 1])\n",
      "Expected new q: 1091.119873046875, torch.Size([256, 1])\n",
      "Log prob: 11.061095237731934, torch.Size([256, 1])\n",
      "Expected q value: 1126.0595703125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1093.5416259765625, torch.Size([256, 1])\n",
      "Expected new q: 1126.5179443359375, torch.Size([256, 1])\n",
      "Log prob: 10.862571716308594, torch.Size([256, 1])\n",
      "Expected q value: 1102.667724609375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1066.969970703125, torch.Size([256, 1])\n",
      "Expected new q: 1102.72802734375, torch.Size([256, 1])\n",
      "Log prob: 10.796079635620117, torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1253 | Reward: 2756.20 | Revenue: 3051.00 | ServedDemand: 347.00 | Reb. Cost: 91.40 | Oper. Cost: 294.80:   3%|▎         | 1253/50000 [12:12:06<421:06:42, 31.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected q value: 1108.29931640625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1075.308349609375, torch.Size([256, 1])\n",
      "Expected new q: 1108.7501220703125, torch.Size([256, 1])\n",
      "Log prob: 10.75635814666748, torch.Size([256, 1])\n",
      "Expected q value: 1124.646484375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1094.37060546875, torch.Size([256, 1])\n",
      "Expected new q: 1124.59423828125, torch.Size([256, 1])\n",
      "Log prob: 10.784582138061523, torch.Size([256, 1])\n",
      "Expected q value: 1134.9658203125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1104.84912109375, torch.Size([256, 1])\n",
      "Expected new q: 1134.9969482421875, torch.Size([256, 1])\n",
      "Log prob: 10.696184158325195, torch.Size([256, 1])\n",
      "Expected q value: 1070.799072265625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1037.06494140625, torch.Size([256, 1])\n",
      "Expected new q: 1071.1339111328125, torch.Size([256, 1])\n",
      "Log prob: 10.850622177124023, torch.Size([256, 1])\n",
      "Expected q value: 1094.68115234375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1056.6676025390625, torch.Size([256, 1])\n",
      "Expected new q: 1095.153564453125, torch.Size([256, 1])\n",
      "Log prob: 10.906046867370605, torch.Size([256, 1])\n",
      "Expected q value: 1095.463623046875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1059.7825927734375, torch.Size([256, 1])\n",
      "Expected new q: 1095.8826904296875, torch.Size([256, 1])\n",
      "Log prob: 10.955224990844727, torch.Size([256, 1])\n",
      "Expected q value: 1104.87255859375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1071.674560546875, torch.Size([256, 1])\n",
      "Expected new q: 1105.37109375, torch.Size([256, 1])\n",
      "Log prob: 10.943117141723633, torch.Size([256, 1])\n",
      "Expected q value: 1096.028564453125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1064.481201171875, torch.Size([256, 1])\n",
      "Expected new q: 1096.3055419921875, torch.Size([256, 1])\n",
      "Log prob: 10.932818412780762, torch.Size([256, 1])\n",
      "Expected q value: 1096.8836669921875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1064.346435546875, torch.Size([256, 1])\n",
      "Expected new q: 1097.1943359375, torch.Size([256, 1])\n",
      "Log prob: 10.840436935424805, torch.Size([256, 1])\n",
      "Expected q value: 1096.888916015625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1061.4100341796875, torch.Size([256, 1])\n",
      "Expected new q: 1097.1165771484375, torch.Size([256, 1])\n",
      "Log prob: 11.052852630615234, torch.Size([256, 1])\n",
      "Expected q value: 1057.3465576171875, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1021.7638549804688, torch.Size([256, 1])\n",
      "Expected new q: 1057.2998046875, torch.Size([256, 1])\n",
      "Log prob: 10.840704917907715, torch.Size([256, 1])\n",
      "Expected q value: 1049.489990234375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1013.3932495117188, torch.Size([256, 1])\n",
      "Expected new q: 1049.6282958984375, torch.Size([256, 1])\n",
      "Log prob: 10.686455726623535, torch.Size([256, 1])\n",
      "Expected q value: 1062.1749267578125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1029.1580810546875, torch.Size([256, 1])\n",
      "Expected new q: 1061.85400390625, torch.Size([256, 1])\n",
      "Log prob: 10.5780029296875, torch.Size([256, 1])\n",
      "Expected q value: 1033.2291259765625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1004.193115234375, torch.Size([256, 1])\n",
      "Expected new q: 1033.41845703125, torch.Size([256, 1])\n",
      "Log prob: 10.875410079956055, torch.Size([256, 1])\n",
      "Expected q value: 1079.019287109375, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1046.4940185546875, torch.Size([256, 1])\n",
      "Expected new q: 1079.5206298828125, torch.Size([256, 1])\n",
      "Log prob: 10.953253746032715, torch.Size([256, 1])\n",
      "Expected q value: 1059.1181640625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1021.4337158203125, torch.Size([256, 1])\n",
      "Expected new q: 1059.1370849609375, torch.Size([256, 1])\n",
      "Log prob: 10.770054817199707, torch.Size([256, 1])\n",
      "Expected q value: 1113.678955078125, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1073.926513671875, torch.Size([256, 1])\n",
      "Expected new q: 1113.656494140625, torch.Size([256, 1])\n",
      "Log prob: 10.903402328491211, torch.Size([256, 1])\n",
      "Expected q value: 1110.863525390625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 1079.805419921875, torch.Size([256, 1])\n",
      "Expected new q: 1111.064697265625, torch.Size([256, 1])\n",
      "Log prob: 10.997995376586914, torch.Size([256, 1])\n",
      "Expected q value: 1015.85009765625, torch.Size([256, 1])\n",
      "torch.Size([256, 8])\n",
      "Target value: 989.8687744140625, torch.Size([256, 1])\n",
      "Expected new q: 1016.1388549804688, torch.Size([256, 1])\n",
      "Log prob: 10.98585319519043, torch.Size([256, 1])\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-133f11f1715f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# take matching step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaxreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpax_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPLEXPATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCPLEXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAC/v7/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpaxreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Select and perform an RL action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/array/daga_data/Github/RL-MoD/env_two_step.py\u001b[0m in \u001b[0;36mpax_step\u001b[0;34m(self, paxAction, CPLEXPATH, PATH)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rebalancing_cost'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpaxAction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# default matching algorithm used if isMatching is True, matching method will need the information of self.acc[t+1], therefore this part cannot be put forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mpaxAction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPLEXPATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCPLEXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaxAction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaxAction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# serving passengers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/array/daga_data/Github/RL-MoD/env_two_step.py\u001b[0m in \u001b[0;36mmatching\u001b[0;34m(self, CPLEXPATH, PATH)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mout_file\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmatchingPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'out_{}.dat'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCPLEXPATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"oplrun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0moutput_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro1/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \"\"\"\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro1/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \"\"\"\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro1/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    773\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    776\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyro1/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1451\u001b[0m                             \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1454\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "# book-keeping variables\n",
    "training_rewards = []\n",
    "training_revenue = []\n",
    "training_served_demand = []\n",
    "training_rebalancing_cost = []\n",
    "training_operating_cost = []\n",
    "\n",
    "# last_t_update = 0\n",
    "train_episodes = 50000 # num_of_episodes_with_same_epsilon x num_of_q_tables x num_epsilons          \n",
    "max_steps = 100 # maximum length of episode\n",
    "epochs = trange(train_episodes) # build tqdm iterator for loop visualization\n",
    "\n",
    "for i_episode in epochs:\n",
    "    try:\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        episode_revenue = 0\n",
    "        episode_served_demand = 0\n",
    "        episode_rebalancing_cost = 0\n",
    "        episode_operating_cost = 0\n",
    "        for step in range(max_steps):\n",
    "            # take matching step \n",
    "            obs, paxreward, done, info = env.pax_step(CPLEXPATH=CPLEXPATH, PATH=\"SAC/v7/\")\n",
    "            episode_reward += paxreward\n",
    "            # Select and perform an RL action\n",
    "            x_ext = torch.tensor([obs[0][n][env.time] for n in env.region] + [env.dacc[n][env.time] for n in env.region] + \\\n",
    "                    [env.price[i,j][t] for t in range(env.time, env.time+1) for i,j in env.demand] + [env.time]).float()\n",
    "            x_temp = torch.tensor([env.demand[i,j][t] for t in range(env.time, env.time+10) for i,j in env.demand]).view(1, 10, 56).float()\n",
    "            state = (x_ext, x_temp)\n",
    "            action_rl = policy_net.get_action(state)\n",
    "\n",
    "            # 1.2 get actual vehicle distributions vi (i.e. (x1*x2*..*xn)*num_vehicles)\n",
    "            v_d = policy_net.get_desired_distribution(torch.tensor(action_rl))\n",
    "\n",
    "            # 1.3 Solve ILP - Minimal Distance Problem \n",
    "            # 1.3.1 collect inputs and build .dat file\n",
    "            t = env.time\n",
    "            accTuple = [(n,int(env.acc[n][t])) for n in env.acc]\n",
    "            accRLTuple = [(n, int(v_d_n)) for n, v_d_n in enumerate(v_d)]\n",
    "            edgeAttr = [(i,j,env.G.edges[i,j]['time']) for i,j in env.G.edges]\n",
    "            modPath = os.getcwd().replace('\\\\','/')+'/mod/'\n",
    "            OPTPath = os.getcwd().replace('\\\\','/')+'/OPT/SAC/v7/'\n",
    "            if not os.path.exists(OPTPath):\n",
    "                os.makedirs(OPTPath)\n",
    "            datafile = OPTPath + f'data_{t}.dat'\n",
    "            resfile = OPTPath + f'res_{t}.dat'\n",
    "            with open(datafile,'w') as file:\n",
    "                file.write('path=\"'+resfile+'\";\\r\\n')\n",
    "                file.write('edgeAttr='+mat2str(edgeAttr)+';\\r\\n')\n",
    "                file.write('accInitTuple='+mat2str(accTuple)+';\\r\\n')\n",
    "                file.write('accRLTuple='+mat2str(accRLTuple)+';\\r\\n')\n",
    "\n",
    "            # 2. execute .mod file and write result on file\n",
    "            modfile = modPath+'minRebDistRebOnly.mod'\n",
    "            if CPLEXPATH is None:\n",
    "                CPLEXPATH = \"/opt/ibm/ILOG/CPLEX_Studio128/opl/bin/x86-64_linux/\"\n",
    "            my_env = os.environ.copy()\n",
    "            my_env[\"LD_LIBRARY_PATH\"] = CPLEXPATH\n",
    "            out_file =  OPTPath + f'out_{t}.dat'\n",
    "            with open(out_file,'w') as output_f:\n",
    "                subprocess.check_call([CPLEXPATH+\"oplrun\", modfile, datafile], stdout=output_f, env=my_env)\n",
    "            output_f.close()\n",
    "\n",
    "            # 3. collect results from file\n",
    "            flow = defaultdict(float)\n",
    "            with open(resfile,'r', encoding=\"utf8\") as file:\n",
    "                for row in file:\n",
    "                    item = row.strip().strip(';').split('=')\n",
    "                    if item[0] == 'flow':\n",
    "                        values = item[1].strip(')]').strip('[(').split(')(')\n",
    "                        for v in values:\n",
    "                            if len(v) == 0:\n",
    "                                continue\n",
    "                            i,j,f = v.split(',')\n",
    "                            flow[int(i),int(j)] = float(f)\n",
    "            rebAction = [flow[i,j] for i,j in env.edges]\n",
    "\n",
    "            # Take step\n",
    "            new_obs, rebreward, done, info = env.reb_step(rebAction)\n",
    "            episode_reward += rebreward\n",
    "            x_ext = torch.tensor([new_obs[0][n][env.time] for n in env.region] + [env.dacc[n][env.time] for n in env.region] + \\\n",
    "                    [env.price[i,j][t] for t in range(env.time, env.time+1) for i,j in env.demand] + [env.time]).float()\n",
    "            x_temp = torch.tensor([env.demand[i,j][t] for t in range(env.time, env.time+10) for i,j in env.demand]).view(1, 10, 56).float()\n",
    "            new_state = (x_ext, x_temp)\n",
    "\n",
    "            # Store the transition in memory\n",
    "            replay_buffer.push(state[0].numpy(), state[1].numpy(), np.array(action_rl), paxreward + rebreward, new_state[0].numpy(), new_state[1].numpy(), done)\n",
    "            \n",
    "            if len(replay_buffer) > batch_size:\n",
    "                soft_q_update(batch_size)\n",
    "                \n",
    "            # Move to the next state\n",
    "            # track performance over episode\n",
    "            episode_revenue += info['revenue']\n",
    "            episode_served_demand += info['served_demand']\n",
    "            episode_rebalancing_cost += info['rebalancing_cost']\n",
    "            episode_operating_cost += info['operating_cost']\n",
    "            obs, state = deepcopy(new_obs), deepcopy(new_state)\n",
    "            \n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        epochs.set_description(f\"Episode {i_episode+1} | Reward: {episode_reward:.2f} | Revenue: {episode_revenue:.2f} | ServedDemand: {episode_served_demand:.2f} \\\n",
    "| Reb. Cost: {episode_rebalancing_cost:.2f} | Oper. Cost: {episode_operating_cost:.2f}\")\n",
    "        #Adding the total reward and reduced epsilon values\n",
    "        training_rewards.append(episode_reward)\n",
    "        training_revenue.append(episode_revenue)\n",
    "        training_served_demand.append(episode_served_demand)\n",
    "        training_rebalancing_cost.append(episode_rebalancing_cost)\n",
    "        training_operating_cost.append(episode_operating_cost)\n",
    "        \n",
    "        if i_episode % 5 == 0:\n",
    "            plot(i_episode+1, training_rewards)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e94b0cb599fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot results with moving average smoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"seaborn-white\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m411\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Avg. Reward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot results with moving average smoothing \n",
    "plt.style.use(\"seaborn-white\")\n",
    "fig = plt.figure(figsize=(12,32))\n",
    "fig.add_subplot(411)\n",
    "plt.plot(moving_average(training_rewards, n=10), label=\"Avg. Reward\")\n",
    "plt.title(\"Avg. Rewards\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"J\")\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(412)\n",
    "plt.plot(moving_average(training_revenue, n=10), label=\"Avg. Revenue\")\n",
    "plt.title(\"Avg. Revenue\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(413)\n",
    "plt.plot(moving_average(training_served_demand, n=10), label=\"Avg. Served Demand\")\n",
    "plt.title(\"Avg. Served Demand\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Served Demand\")\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(414)\n",
    "plt.plot(moving_average(training_rebalancing_cost, n=10), label=\"Avg. Reb. Cost\")\n",
    "plt.title(\"Avg. Reb. Cost\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three levels\n",
    "scenario = Scenario(sd=10,demand_input = {(1,6):2, (0,7):2, 'default':0.1}, fix_price=True) # uni-directional\n",
    "env = AMoD(scenario)\n",
    "model.env = env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Episode 1 | Reward: 2728.60 | Revenue: 3039.00 | ServedDemand: 318.00 | Reb. Cost: 107.8 | Oper. Cost: 310.40:   0%|          | 0/100 [00:05<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "test_episodes = 100\n",
    "max_steps = 100\n",
    "epochs = trange(test_episodes) # build tqdm iterator for loop visualization\n",
    "np.random.seed(10)\n",
    "\n",
    "test_rewards = []\n",
    "test_revenue = []\n",
    "test_served_demand = []\n",
    "test_rebalancing_cost = []\n",
    "test_operating_cost = []\n",
    "action_list = []\n",
    "\n",
    "for episode in epochs:\n",
    "    try:\n",
    "        episode_reward = 0\n",
    "        episode_revenue = 0\n",
    "        episode_served_demand = 0\n",
    "        episode_rebalancing_cost = 0\n",
    "        episode_operating_cost = 0\n",
    "        episode_action_list = []\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        while(not done):\n",
    "            # take matching step \n",
    "            obs, paxreward, done, info = env.pax_step(CPLEXPATH=CPLEXPATH, PATH=\"AC/v9/\")\n",
    "            episode_reward += paxreward\n",
    "            # Select and perform an RL action\n",
    "            x_ext = torch.tensor([obs[0][n][env.time] for n in env.region] + [env.dacc[n][env.time] for n in env.region] + \\\n",
    "                    [env.price[i,j][t] for t in range(env.time, env.time+1) for i,j in env.demand] + [env.time]).float()\n",
    "            x_temp = torch.tensor([env.demand[i,j][t] for t in range(env.time, env.time+10) for i,j in env.demand]).view(1, 10, 56).float()\n",
    "            state = (x_ext, x_temp)\n",
    "            with torch.no_grad():\n",
    "                c, _ = model(state[0], state[1])\n",
    "                action_rl = list(c.numpy()/c.numpy().sum())\n",
    "            episode_action_list.append(action_rl)\n",
    "\n",
    "            # 1.2 get actual vehicle distributions vi (i.e. (x1*x2*..*xn)*num_vehicles)\n",
    "            v_d = model.get_desired_distribution(torch.tensor(action_rl))\n",
    "\n",
    "            # 1.3 Solve ILP - Minimal Distance Problem \n",
    "            # 1.3.1 collect inputs and build .dat file\n",
    "            t = env.time\n",
    "            accTuple = [(n,int(env.acc[n][t])) for n in env.acc]\n",
    "            accRLTuple = [(n, int(v_d_n)) for n, v_d_n in enumerate(v_d)]\n",
    "            edgeAttr = [(i,j,env.G.edges[i,j]['time']) for i,j in env.G.edges]\n",
    "            modPath = os.getcwd().replace('\\\\','/')+'/mod/'\n",
    "            OPTPath = os.getcwd().replace('\\\\','/')+'/OPT/AC/v9/'\n",
    "            if not os.path.exists(OPTPath):\n",
    "                os.makedirs(OPTPath)\n",
    "            datafile = OPTPath + f'data_{t}.dat'\n",
    "            resfile = OPTPath + f'res_{t}.dat'\n",
    "            with open(datafile,'w') as file:\n",
    "                file.write('path=\"'+resfile+'\";\\r\\n')\n",
    "                file.write('edgeAttr='+mat2str(edgeAttr)+';\\r\\n')\n",
    "                file.write('accInitTuple='+mat2str(accTuple)+';\\r\\n')\n",
    "                file.write('accRLTuple='+mat2str(accRLTuple)+';\\r\\n')\n",
    "\n",
    "            # 2. execute .mod file and write result on file\n",
    "            modfile = modPath+'minRebDistRebOnly.mod'\n",
    "            if CPLEXPATH is None:\n",
    "                CPLEXPATH = \"/opt/ibm/ILOG/CPLEX_Studio128/opl/bin/x86-64_linux/\"\n",
    "            my_env = os.environ.copy()\n",
    "            my_env[\"LD_LIBRARY_PATH\"] = CPLEXPATH\n",
    "            out_file =  OPTPath + f'out_{t}.dat'\n",
    "            with open(out_file,'w') as output_f:\n",
    "                subprocess.check_call([CPLEXPATH+\"oplrun\", modfile, datafile], stdout=output_f, env=my_env)\n",
    "            output_f.close()\n",
    "\n",
    "            # 3. collect results from file\n",
    "            flow = defaultdict(float)\n",
    "            with open(resfile,'r', encoding=\"utf8\") as file:\n",
    "                for row in file:\n",
    "                    item = row.strip().strip(';').split('=')\n",
    "                    if item[0] == 'flow':\n",
    "                        values = item[1].strip(')]').strip('[(').split(')(')\n",
    "                        for v in values:\n",
    "                            if len(v) == 0:\n",
    "                                continue\n",
    "                            i,j,f = v.split(',')\n",
    "                            flow[int(i),int(j)] = float(f)\n",
    "            rebAction = [flow[i,j] for i,j in env.edges]\n",
    "\n",
    "            new_obs, rebreward, done, info = env.reb_step(rebAction)\n",
    "            episode_reward += rebreward\n",
    "            x_ext = torch.tensor([new_obs[0][n][env.time] for n in env.region] + [env.dacc[n][env.time] for n in env.region] + \\\n",
    "                    [env.price[i,j][t] for t in range(env.time, env.time+1) for i,j in env.demand] + [env.time]).float()\n",
    "            x_temp = torch.tensor([env.demand[i,j][t] for t in range(env.time, env.time+10) for i,j in env.demand]).view(1, 10, 56).float()\n",
    "            new_state = (x_ext, x_temp)\n",
    "            \n",
    "            episode_served_demand += info['served_demand']\n",
    "            episode_rebalancing_cost += info['rebalancing_cost']\n",
    "            episode_operating_cost += info['operating_cost']\n",
    "            episode_revenue += info['revenue']\n",
    "        epochs.set_description(f\"Episode {episode+1} | Reward: {episode_reward:.2f} | Revenue: {episode_revenue:.2f} | ServedDemand: {episode_served_demand:.2f} \\\n",
    "| Reb. Cost: {episode_rebalancing_cost} | Oper. Cost: {episode_operating_cost:.2f}\")\n",
    "        #Adding the total reward and reduced epsilon values\n",
    "        test_rewards.append(episode_reward)\n",
    "        test_revenue.append(episode_revenue)\n",
    "        test_served_demand.append(episode_served_demand)\n",
    "        test_rebalancing_cost.append(episode_rebalancing_cost)\n",
    "        test_operating_cost.append(episode_operating_cost)\n",
    "        action_list.append(episode_action_list)\n",
    "        break\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
