{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_two_step import Scenario, AMoD\n",
    "from MPC import MPC\n",
    "import os\n",
    "from util import mat2str\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "device = 'linux'\n",
    "if device == 'windows':\n",
    "    CPLEXPATH = \"C:/Program Files/ibm/ILOG/CPLEX_Studio1210/opl/bin/x64_win64/\"\n",
    "elif device == 'mac':\n",
    "    CPLEXPATH = \"/Applications/CPLEX_Studio1210/opl/bin/x86-64_osx/\"\n",
    "elif device == 'linux':\n",
    "    CPLEXPATH = \"/opt/ibm/ILOG/CPLEX_Studio128/opl/bin/x86-64_linux/\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_vehicles():\n",
    "    \"\"\"\n",
    "    Count total number of available vehicles.\n",
    "    \"\"\"\n",
    "    return np.sum([env.acc[region][env.time] for region in env.region])\n",
    "    \n",
    "def get_desired_distribution(action_rl):\n",
    "    \"\"\"\n",
    "    Given a RL action, returns the desired number of vehicles in each area.\n",
    "    \"\"\"\n",
    "    v_d = action_rl*get_available_vehicles()\n",
    "    return list(v_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three levels\n",
    "scenario = Scenario(sd=10,demand_input = {(1,6):2, (0,7):2, 'default':0.1}, fix_price=True) # uni-directional\n",
    "env = AMoD(scenario)\n",
    "mpc = MPC(env, CPLEXPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1 | Reward: 2219.00 | Revenue: 2493.00 | ServedDemand: 293.00 | Reb. Cost: 107.80000000000004 | Oper. Cost: 274.00:   0%|          | 0/100 [00:03<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "test_episodes = 100\n",
    "max_steps = 100\n",
    "epochs = trange(test_episodes) # build tqdm iterator for loop visualization\n",
    "np.random.seed(10)\n",
    "\n",
    "test_rewards = []\n",
    "test_revenue = []\n",
    "test_served_demand = []\n",
    "test_rebalancing_cost = []\n",
    "test_operating_cost = []\n",
    "action_list = []\n",
    "\n",
    "for episode in epochs:\n",
    "    try:\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        episode_revenue = 0\n",
    "        episode_served_demand = 0\n",
    "        episode_rebalancing_cost = 0\n",
    "        episode_operating_cost = 0\n",
    "        episode_action_list = []\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        while(not done):\n",
    "            res_path='random'\n",
    "            obs, reward, done, info = env.pax_step(CPLEXPATH=CPLEXPATH,PATH=res_path)\n",
    "            episode_reward += reward \n",
    "            \n",
    "            action_rl = np.random.dirichlet(alpha=np.ones(8))\n",
    "            v_d = get_desired_distribution(action_rl)\n",
    "            \n",
    "            t = env.time\n",
    "            accTuple = [(n,int(env.acc[n][t])) for n in env.acc]\n",
    "            accRLTuple = [(n, int(v_d_n)) for n, v_d_n in enumerate(v_d)]\n",
    "            edgeAttr = [(i,j,env.G.edges[i,j]['time']) for i,j in env.G.edges]\n",
    "            modPath = os.getcwd().replace('\\\\','/')+'/mod/'\n",
    "            OPTPath = os.getcwd().replace('\\\\','/')+'/OPT/random/v1/'\n",
    "            if not os.path.exists(OPTPath):\n",
    "                os.makedirs(OPTPath)\n",
    "            datafile = OPTPath + f'data_{t}.dat'\n",
    "            resfile = OPTPath + f'res_{t}.dat'\n",
    "            with open(datafile,'w') as file:\n",
    "                file.write('path=\"'+resfile+'\";\\r\\n')\n",
    "                file.write('edgeAttr='+mat2str(edgeAttr)+';\\r\\n')\n",
    "                file.write('accInitTuple='+mat2str(accTuple)+';\\r\\n')\n",
    "                file.write('accRLTuple='+mat2str(accRLTuple)+';\\r\\n')\n",
    "\n",
    "            # 2. execute .mod file and write result on file\n",
    "            modfile = modPath+'minRebDistRebOnly.mod'\n",
    "            if CPLEXPATH is None:\n",
    "                CPLEXPATH = \"/opt/ibm/ILOG/CPLEX_Studio128/opl/bin/x86-64_linux/\"\n",
    "            my_env = os.environ.copy()\n",
    "            my_env[\"LD_LIBRARY_PATH\"] = CPLEXPATH\n",
    "            out_file =  OPTPath + f'out_{t}.dat'\n",
    "            with open(out_file,'w') as output_f:\n",
    "                subprocess.check_call([CPLEXPATH+\"oplrun\", modfile, datafile], stdout=output_f, env=my_env)\n",
    "            output_f.close()\n",
    "\n",
    "            # 3. collect results from file\n",
    "            flow = defaultdict(float)\n",
    "            with open(resfile,'r', encoding=\"utf8\") as file:\n",
    "                for row in file:\n",
    "                    item = row.strip().strip(';').split('=')\n",
    "                    if item[0] == 'flow':\n",
    "                        values = item[1].strip(')]').strip('[(').split(')(')\n",
    "                        for v in values:\n",
    "                            if len(v) == 0:\n",
    "                                continue\n",
    "                            i,j,f = v.split(',')\n",
    "                            flow[int(i),int(j)] = float(f)\n",
    "            rebAction = [flow[i,j] for i,j in env.edges]\n",
    "            \n",
    "            obs, reward, done, info = env.reb_step(rebAction)\n",
    "            episode_reward += reward\n",
    "            episode_served_demand += info['served_demand']\n",
    "            episode_rebalancing_cost += info['rebalancing_cost']\n",
    "            episode_operating_cost += info['operating_cost']\n",
    "            episode_revenue += info['revenue']\n",
    "        epochs.set_description(f\"Episode {episode+1} | Reward: {episode_reward:.2f} | Revenue: {episode_revenue:.2f} | ServedDemand: {episode_served_demand:.2f} \\\n",
    "| Reb. Cost: {episode_rebalancing_cost} | Oper. Cost: {episode_operating_cost:.2f}\")\n",
    "        #Adding the total reward and reduced epsilon values\n",
    "        test_rewards.append(episode_reward)\n",
    "        test_revenue.append(episode_revenue)\n",
    "        test_served_demand.append(episode_served_demand)\n",
    "        test_rebalancing_cost.append(episode_rebalancing_cost)\n",
    "        test_operating_cost.append(episode_operating_cost)\n",
    "        action_list.append(episode_action_list)\n",
    "        break\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
