{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Tri-level MPC\n",
       "\\begin{align}\n",
       "\\max_{\\mathbf{d,r,\\hat{n}}} \\quad &\\sum_{t\\in\\mathcal{T}}\\sum_{(i,j) \\in \\mathcal{E}}d_{ijt}p_{ijt} \n",
       "- \\beta\\sum_{t\\in\\mathcal{T}}\\sum_{(i,j) \\in \\mathcal{E}}(r_{ijt}+d_{ijt})\\tau_{ij} \\\\\n",
       "\\rm{s.t.}\\quad & n_{i,t+1} = n_{it} - \\sum_{j: (i,j)\\in\\mathcal{E}}(d_{ijt}+r_{ijt}) \n",
       "    + \\sum_{j: (j,i)\\in\\mathcal{E}}(d_{ij,t-\\tau_{ij}}+r_{ij,t-\\tau_{ij}}) \\\\\n",
       "    & \\sum_{j:(i,j)\\in\\mathcal{E}}(d_{ijt}+r_{ijt}) \\leq n_{it} \\\\\n",
       "    & \\mathbf{d}_t \\in F(\\mathbf{n}_t) \\\\\n",
       "    & \\mathbf{r}_t \\in G(\\mathbf{n}_t, \\mathbf{\\hat{n}}_t) \\\\\n",
       "    & \\hat{n} \\in \\mathbb{Z}_+\n",
       "\\end{align} \n",
       "\n",
       "$F(\\cdot)$ is the set of optimal solution of the matching problem\n",
       "\\begin{align}\n",
       "\\max_{\\mathbf{d}} \\quad & \\sum_{(i,j)\\in\\mathcal{E}}d_{ijt}p_{ijt} \\\\\n",
       "\\quad & \\sum_{j:(i,j) in \\mathcal{E}}d_{ijt} \\leq n_{it}\\\\\n",
       "& d_{ijt} \\leq \\lambda_{ijt} \n",
       "\\end{align}\n",
       "\n",
       "$G()$ is the set of optimal solution of the rebalancing problem \n",
       "\\begin{align}\n",
       "\\min_{\\mathbf{r}} \\quad & \\sum_{(i,j)\\in\\mathcal{E}}r_{ijt}\\tau_{ij} \\\\\n",
       "\\quad & \\sum_{j:(j,i)\\in\\mathcal{E}}r_{ij} - \\sum_{j:(i,j)\\in\\mathcal{E}}r_{ij} \\geq \\hat{n}_{it} - n_{it}\n",
       "& \\sum_{j:(i,j) in \\mathcal{E}}r_{ijt} \\leq n_{it}\\\\\n",
       "\\end{align}\n",
       "\n",
       "One alternative for G is the set of optimal solution of the rebalancing problem\n",
       "\\begin{align}\n",
       "\\min_{\\mathbf{r}} \\quad & \\sum_{(i,j)\\in\\mathcal{E}}r_{ijt}\\tau_{ij} \\\\\n",
       "\\quad & \\sum_{j:(j,i)\\in\\mathcal{E}}r_{ij} = a_{it} \\\\\n",
       "& \\sum_{j:(i,j)\\in\\mathcal{E}}r_{ij} = b_{it}\\\\\n",
       "\\end{align}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "Tri-level MPC\n",
    "\\begin{align}\n",
    "\\max_{\\mathbf{d,r,\\hat{n}}} \\quad &\\sum_{t\\in\\mathcal{T}}\\sum_{(i,j) \\in \\mathcal{E}}d_{ijt}p_{ijt} \n",
    "- \\beta\\sum_{t\\in\\mathcal{T}}\\sum_{(i,j) \\in \\mathcal{E}}(r_{ijt}+d_{ijt})\\tau_{ij} \\\\\n",
    "\\rm{s.t.}\\quad & n_{i,t+1} = n_{it} - \\sum_{j: (i,j)\\in\\mathcal{E}}(d_{ijt}+r_{ijt}) \n",
    "    + \\sum_{j: (j,i)\\in\\mathcal{E}}(d_{ij,t-\\tau_{ij}}+r_{ij,t-\\tau_{ij}}) \\\\\n",
    "    & \\sum_{j:(i,j)\\in\\mathcal{E}}(d_{ijt}+r_{ijt}) \\leq n_{it} \\\\\n",
    "    & \\mathbf{d}_t \\in F(\\mathbf{n}_t) \\\\\n",
    "    & \\mathbf{r}_t \\in G(\\mathbf{n}_t, \\mathbf{\\hat{n}}_t) \\\\\n",
    "    & \\hat{n} \\in \\mathbb{Z}_+\n",
    "\\end{align} \n",
    "\n",
    "$F(\\cdot)$ is the set of optimal solution of the matching problem\n",
    "\\begin{align}\n",
    "\\max_{\\mathbf{d}} \\quad & \\sum_{(i,j)\\in\\mathcal{E}}d_{ijt}p_{ijt} \\\\\n",
    "\\quad & \\sum_{j:(i,j) in \\mathcal{E}}d_{ijt} \\leq n_{it}\\\\\n",
    "& d_{ijt} \\leq \\lambda_{ijt} \n",
    "\\end{align}\n",
    "\n",
    "$G()$ is the set of optimal solution of the rebalancing problem \n",
    "\\begin{align}\n",
    "\\min_{\\mathbf{r}} \\quad & \\sum_{(i,j)\\in\\mathcal{E}}r_{ijt}\\tau_{ij} \\\\\n",
    "\\quad & \\sum_{j:(j,i)\\in\\mathcal{E}}r_{ij} - \\sum_{j:(i,j)\\in\\mathcal{E}}r_{ij} \\geq \\hat{n}_{it} - n_{it}\n",
    "& \\sum_{j:(i,j) in \\mathcal{E}}r_{ijt} \\leq n_{it}\\\\\n",
    "\\end{align}\n",
    "\n",
    "One alternative for G is the set of optimal solution of the rebalancing problem\n",
    "\\begin{align}\n",
    "\\min_{\\mathbf{r}} \\quad & \\sum_{(i,j)\\in\\mathcal{E}}r_{ijt}\\tau_{ij} \\\\\n",
    "\\quad & \\sum_{j:(j,i)\\in\\mathcal{E}}r_{ij} = a_{it} \\\\\n",
    "& \\sum_{j:(i,j)\\in\\mathcal{E}}r_{ij} = b_{it}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-44f7dcaf4ece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_two_step\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAMoD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStar2Complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmat2str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMPC\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.envs.env_two_step import Scenario, AMoD, Star2Complete\n",
    "from src.misc.utils import mat2str, dictsum\n",
    "from src.algos.MPC import MPC\n",
    "import os\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "platform = 'linux'\n",
    "if platform == 'windows':\n",
    "    CPLEXPATH = \"C:/Program Files/ibm/ILOG/CPLEX_Studio1210/opl/bin/x64_win64/\"\n",
    "elif platform == 'mac':\n",
    "    CPLEXPATH = \"/Applications/CPLEX_Studio1210/opl/bin/x86-64_osx/\"\n",
    "elif platform == 'linux':\n",
    "    CPLEXPATH = \"/opt/ibm/ILOG/CPLEX_Studio1210/opl/bin/x86-64_linux/\"\n",
    "    \n",
    "def solveRebFlow(env,res_path,desiredAcc,CPLEXPATH):\n",
    "    t = env.time\n",
    "    accRLTuple = [(n,int(round(desiredAcc[n]))) for n in desiredAcc]\n",
    "    accTuple = [(n,int(env.acc[n][t+1])) for n in env.acc]\n",
    "    edgeAttr = [(i,j,env.G.edges[i,j]['time']) for i,j in env.G.edges]\n",
    "    modPath = os.getcwd().replace('\\\\','/')+'/mod/'\n",
    "    OPTPath = os.getcwd().replace('\\\\','/')+'/MPC/'+res_path\n",
    "    if not os.path.exists(OPTPath):\n",
    "        os.makedirs(OPTPath)\n",
    "    datafile = OPTPath + f'data_{t}.dat'\n",
    "    resfile = OPTPath + f'res_{t}.dat'\n",
    "    with open(datafile,'w') as file:\n",
    "        file.write('path=\"'+resfile+'\";\\r\\n')\n",
    "        file.write('edgeAttr='+mat2str(edgeAttr)+';\\r\\n')\n",
    "        file.write('accInitTuple='+mat2str(accTuple)+';\\r\\n')\n",
    "        file.write('accRLTuple='+mat2str(accRLTuple)+';\\r\\n')\n",
    "    modfile = modPath+'minRebDistRebOnly.mod'\n",
    "    if CPLEXPATH is None:\n",
    "        CPLEXPATH = \"/opt/ibm/ILOG/CPLEX_Studio128/opl/bin/x86-64_linux/\"\n",
    "    my_env = os.environ.copy()\n",
    "    my_env[\"LD_LIBRARY_PATH\"] = CPLEXPATH\n",
    "    out_file =  OPTPath + f'out_{t}.dat'\n",
    "    with open(out_file,'w') as output_f:\n",
    "        subprocess.check_call([CPLEXPATH+\"oplrun\", modfile, datafile], stdout=output_f, env=my_env)\n",
    "    output_f.close()\n",
    "\n",
    "    # 3. collect results from file\n",
    "    flow = defaultdict(float)\n",
    "    with open(resfile,'r', encoding=\"utf8\") as file:\n",
    "        for row in file:\n",
    "            item = row.strip().strip(';').split('=')\n",
    "            if item[0] == 'flow':\n",
    "                values = item[1].strip(')]').strip('[(').split(')(')\n",
    "                for v in values:\n",
    "                    if len(v) == 0:\n",
    "                        continue\n",
    "                    i,j,f = v.split(',')\n",
    "                    flow[int(i),int(j)] = float(f)\n",
    "    action = [flow[i,j] for i,j in env.edges]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPC: Reward 179360.74319365056, Revenue 209683.14319365067,Served demand 20848.0, Rebalancing Cost 10033.999999999998, Operational Cost 30322.399999999994\n",
      "25479 0.8182424741944346\n"
     ]
    }
   ],
   "source": [
    "# MPC exact\n",
    "#scenario = Star2Complete(sd = 10, grid_travel_time = 2, T = 16, star_demand = 7.5, complete_demand=1.5, \n",
    "#                         star_center = [9,10,13,14], beta=0.9, alpha = 0.5, ninit = 200, fix_price = True)\n",
    "\n",
    "scenario = Star2Complete(sd = 10, grid_travel_time = 2, star_demand = 6, complete_demand=0.15, \n",
    "                         star_center = [5,6,9,10], alpha = 0.3, ninit = 200, fix_price = True)\n",
    "\n",
    "env1 = AMoD(scenario)\n",
    "mpc = MPC(env1, CPLEXPATH,T=20)\n",
    "opt_rew = []\n",
    "obs = env1.reset()\n",
    "done = False\n",
    "served = 0\n",
    "rebcost = 0\n",
    "opcost = 0\n",
    "revenue = 0\n",
    "while(not done):\n",
    "    paxAction, rebAction = mpc.MPC_exact() \n",
    "    obs, reward1, done, info = env1.pax_step(paxAction)\n",
    "    \n",
    "    obs, reward2, done, info = env1.reb_step(rebAction)\n",
    "    opt_rew.append(reward1+reward2) \n",
    "    served += info['served_demand']\n",
    "    rebcost += info['rebalancing_cost']\n",
    "    opcost += info['operating_cost']\n",
    "    revenue += info['revenue'] \n",
    "print(f'MPC: Reward {sum(opt_rew)}, Revenue {revenue},Served demand {served}, Rebalancing Cost {rebcost}, Operational Cost {opcost}')\n",
    "demand = sum([env1.demand[i,j][t] for i,j in env1.demand for t in range(0,60)])\n",
    "print(demand, served/demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downgraded MPC (three levels): Reward 172345.22, Revenue 202684.02,Served demand 19691.00, Rebalancing Cost 10285.60, Operational Cost 30338.80\n",
      "25479 0.772832528749166\n"
     ]
    }
   ],
   "source": [
    "# three levels\n",
    "# scenario = Star2Complete(sd = 10, grid_travel_time = 2, T = 16, star_demand = 7.5, complete_demand=1.5, \n",
    "#                         star_center = [9,10,13,14], beta=0.9, alpha = 0.5, ninit = 200, fix_price = True)\n",
    "\n",
    "scenario = Star2Complete(sd = 10, grid_travel_time = 2, star_demand = 6, complete_demand=0.15, \n",
    "                         star_center = [5,6,9,10], alpha = 0.3, ninit = 200, fix_price = True)\n",
    "\n",
    "env = AMoD(scenario)\n",
    "mpc = MPC(env, CPLEXPATH, T = 12)\n",
    "opt_rew = []\n",
    "obs = env.reset()\n",
    "done = False\n",
    "served = 0\n",
    "rebcost = 0\n",
    "opcost = 0\n",
    "revenue = 0\n",
    "paxFlow = dict()\n",
    "rebFlow = dict()\n",
    "desiredAcc = dict()\n",
    "rebAction = dict()\n",
    "while(not done):\n",
    "    t = env.time\n",
    "    res_path = 'tri-level/'\n",
    "    desiredAcc[t], paxFlow[t], rebFlow[t] = mpc.tri_level() \n",
    "    obs, reward1, done, info = env.pax_step(CPLEXPATH = CPLEXPATH, PATH = res_path)\n",
    "    \n",
    "    rebAction[t] = solveRebFlow(env,'reb_'+res_path,desiredAcc[t],CPLEXPATH)\n",
    "    obs, reward2, done, info = env.reb_step(rebAction[t])\n",
    "    opt_rew.append(reward1+reward2) \n",
    "    served += info['served_demand']\n",
    "    rebcost += info['rebalancing_cost']\n",
    "    opcost += info['operating_cost']\n",
    "    revenue += info['revenue']\n",
    "print(f'Downgraded MPC (three levels): Reward {sum(opt_rew):.2f}, Revenue {revenue:.2f},Served demand {served:.2f}, Rebalancing Cost {rebcost:.2f}, Operational Cost {opcost:.2f}')\n",
    "demand = sum([env.demand[i,j][t] for i,j in env.demand for t in range(0,60)])\n",
    "print(demand, served/demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized actions: Reward 148384.90, Revenue 173380.50,Served demand 15731.00, Rebalancing Cost 8365.60, Operational Cost 24995.60\n",
      "25479 0.6174104164213666\n"
     ]
    }
   ],
   "source": [
    "# randomized actions\n",
    "#scenario = Star2Complete(sd = 10, grid_travel_time = 2, T = 16, star_demand = 7.5, complete_demand=1.5, \n",
    "#                         star_center = [9,10,13,14], beta=0.9, alpha = 0.5, ninit = 200, fix_price = True)\n",
    "\n",
    "scenario = Star2Complete(sd = 10, grid_travel_time = 2, star_demand = 6, complete_demand=0.15, \n",
    "                         star_center = [5,6,9,10], alpha = 0.3, ninit = 200, fix_price = True)\n",
    "\n",
    "env = AMoD(scenario)\n",
    "mpc = MPC(env, CPLEXPATH)\n",
    "opt_rew = []\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "served = 0\n",
    "rebcost = 0\n",
    "opcost = 0\n",
    "revenue = 0\n",
    "while(not done):\n",
    "    #print(env.time)\n",
    "    res_path = 'randomized/'\n",
    "    \n",
    "\n",
    "    obs, reward1, done, info = env.pax_step(CPLEXPATH = CPLEXPATH, PATH = res_path)\n",
    "    prob = np.ones(env.nregion)/env.nregion\n",
    "    desiredAcc = {i: int(prob[i] *dictsum(env.acc,env.time+1))for i in range(len(env.region))}\n",
    "    rebAction = solveRebFlow(env,'reb_'+res_path,desiredAcc,CPLEXPATH)\n",
    "    obs, reward2, done, info = env.reb_step(rebAction)\n",
    "    opt_rew.append(reward1+reward2) \n",
    "    served += info['served_demand']\n",
    "    rebcost += info['rebalancing_cost']\n",
    "    opcost += info['operating_cost']\n",
    "    revenue += info['revenue']\n",
    "print(f'Randomized actions: Reward {sum(opt_rew):.2f}, Revenue {revenue:.2f},Served demand {served:.2f}, Rebalancing Cost {rebcost:.2f}, Operational Cost {opcost:.2f}')\n",
    "demand = sum([env.demand[i,j][t] for i,j in env.demand for t in range(0,60)])\n",
    "print(demand, served/demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downgraded MPC (MPC + rebalancing): Reward 2596.90998186934, Revenue 2915.709981869339,Served demand 391.0, Rebalancing Cost 92.60000000000002, Operational Cost 321.0\n"
     ]
    }
   ],
   "source": [
    "# bi-level MPC + rebalancing\n",
    "scenario = Scenario(sd=10,demand_input = {(1,6):2, (0,7):2, 'default':0.1}) # uni-directional\n",
    "env = AMoD(scenario)\n",
    "mpc = MPC(env, CPLEXPATH)\n",
    "opt_rew = []\n",
    "obs = env.reset()\n",
    "done = False\n",
    "served = 0\n",
    "rebcost = 0\n",
    "opcost = 0\n",
    "revenue = 0\n",
    "while(not done):\n",
    "    res_path = 'bi-level-rebalancing/'\n",
    "    paxAction, desiredAcc = mpc.bi_level_rebalancing() \n",
    "    obs, reward, done, info = env.pax_step(paxAction)\n",
    "    opt_rew.append(reward) \n",
    "    rebAction = solveRebFlow(env,'reb_'+res_path,desiredAcc,CPLEXPATH)\n",
    "    obs, reward, done, info = env.reb_step(rebAction)\n",
    "    served += info['served_demand']\n",
    "    rebcost += info['rebalancing_cost']\n",
    "    opcost += info['operating_cost']\n",
    "    revenue += info['revenue']\n",
    "print(f'Downgraded MPC (MPC + rebalancing): Reward {sum(opt_rew)}, Revenue {revenue},Served demand {served}, Rebalancing Cost {rebcost}, Operational Cost {opcost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downgraded MPC (matching + MPC): Reward 2535.8927418873122, Revenue 2864.8927418873122,Served demand 404.0, Rebalancing Cost 93.80000000000004, Operational Cost 330.4\n"
     ]
    }
   ],
   "source": [
    "# bi-level MPC + matching\n",
    "scenario = Scenario(sd=10,demand_input = {(1,6):2, (0,7):2, 'default':0.1}) # uni-directional\n",
    "env = AMoD(scenario)\n",
    "mpc = MPC(env, CPLEXPATH)\n",
    "opt_rew = []\n",
    "obs = env.reset()\n",
    "done = False\n",
    "served = 0\n",
    "rebcost = 0\n",
    "opcost = 0\n",
    "revenue = 0\n",
    "while(not done):\n",
    "    res_path = 'bi-level-rebalancing/'\n",
    "    paxAction = env.matching(CPLEXPATH,res_path)\n",
    "    obs, reward, done, info = env.pax_step(paxAction)\n",
    "    opt_rew.append(reward) \n",
    "    rebAction = mpc.bi_level_matching()\n",
    "    obs, reward, done, info = env.reb_step(rebAction)\n",
    "    served += info['served_demand']\n",
    "    rebcost += info['rebalancing_cost']\n",
    "    opcost += info['operating_cost']\n",
    "    revenue += info['revenue']\n",
    "print(f'Downgraded MPC (matching + MPC): Reward {sum(opt_rew)}, Revenue {revenue},Served demand {served}, Rebalancing Cost {rebcost}, Operational Cost {opcost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downgraded MPC (MPC + rebalancing-2-actions): Reward 2667.126040062874, Revenue 2993.326040062872,Served demand 404.0, Rebalancing Cost 92.4, Operational Cost 327.59999999999997\n"
     ]
    }
   ],
   "source": [
    "from env_two_step import Scenario, AMoD\n",
    "from MPC import MPC\n",
    "import os\n",
    "from util import mat2str\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "\n",
    "device = 'windows'\n",
    "if device == 'windows':\n",
    "    CPLEXPATH = \"C:/Program Files/ibm/ILOG/CPLEX_Studio1210/opl/bin/x64_win64/\"\n",
    "elif device == 'mac':\n",
    "    CPLEXPATH = \"/Applications/CPLEX_Studio1210/opl/bin/x86-64_osx/\"\n",
    "elif device == 'linux':\n",
    "    CPLEXPATH = \"/home/yangkaidi07/CPLEX_Studio1210/opl/bin/x86-64_linux/\"\n",
    "    \n",
    "def solveRebFlow2Action(env,res_path,departure,arrival,CPLEXPATH):\n",
    "    t = env.time\n",
    "    accTuple = [(n,int(env.acc[n][t]), departure[n], arrival[n]) for n in env.acc]\n",
    "    edgeAttr = [(i,j,env.G.edges[i,j]['time']) for i,j in env.G.edges]\n",
    "    modPath = os.getcwd().replace('\\\\','/')+'/mod/'\n",
    "    OPTPath = os.getcwd().replace('\\\\','/')+'/MPC/'+res_path\n",
    "    if not os.path.exists(OPTPath):\n",
    "        os.makedirs(OPTPath)\n",
    "    datafile = OPTPath + f'data_{t}.dat'\n",
    "    resfile = OPTPath + f'res_{t}.dat'\n",
    "    with open(datafile,'w') as file:\n",
    "        file.write('path=\"'+resfile+'\";\\r\\n')\n",
    "        file.write('edgeAttr='+mat2str(edgeAttr)+';\\r\\n')\n",
    "        file.write('accInitTuple='+mat2str(accTuple)+';\\r\\n')\n",
    "    modfile = modPath+'minRebDistReb2Actions.mod' \n",
    "    my_env = os.environ.copy()\n",
    "    my_env[\"LD_LIBRARY_PATH\"] = CPLEXPATH\n",
    "    out_file =  OPTPath + f'out_{t}.dat'\n",
    "    with open(out_file,'w') as output_f:\n",
    "        subprocess.check_call([CPLEXPATH+\"oplrun\", modfile, datafile], stdout=output_f, env=my_env)\n",
    "    output_f.close()\n",
    "\n",
    "    # 3. collect results from file\n",
    "    flow = defaultdict(float)\n",
    "    with open(resfile,'r', encoding=\"utf8\") as file:\n",
    "        for row in file:\n",
    "            item = row.strip().strip(';').split('=')\n",
    "            if item[0] == 'flow':\n",
    "                values = item[1].strip(')]').strip('[(').split(')(')\n",
    "                for v in values:\n",
    "                    if len(v) == 0:\n",
    "                        continue\n",
    "                    i,j,f = v.split(',')\n",
    "                    flow[int(i),int(j)] = float(f)\n",
    "    action = [flow[i,j] for i,j in env.edges]\n",
    "    return action\n",
    "\n",
    "# bi-level MPC + rebalancing 2 actions\n",
    "scenario = Scenario(sd=10,demand_input = {(1,6):2, (0,7):2, 'default':0.1}) # uni-directional\n",
    "env = AMoD(scenario)\n",
    "mpc = MPC(env, CPLEXPATH)\n",
    "opt_rew = []\n",
    "obs = env.reset()\n",
    "done = False\n",
    "served = 0\n",
    "rebcost = 0\n",
    "opcost = 0\n",
    "revenue = 0\n",
    "while(not done):\n",
    "    res_path = 'bi-level-rebalancing-2-actions/'\n",
    "    paxAction, departure,arrival = mpc.bi_level_rebalancing_2_actions() \n",
    "    obs, reward, done, info = env.pax_step(paxAction)\n",
    "    opt_rew.append(reward) \n",
    "    rebAction = solveRebFlow2Action(env,'reb_'+res_path,departure,arrival,CPLEXPATH)\n",
    "    obs, reward, done, info = env.reb_step(rebAction)\n",
    "    served += info['served_demand']\n",
    "    rebcost += info['rebalancing_cost']\n",
    "    opcost += info['operating_cost']\n",
    "    revenue += info['revenue']\n",
    "print(f'Downgraded MPC (MPC + rebalancing-2-actions): Reward {sum(opt_rew)}, Revenue {revenue},Served demand {served}, Rebalancing Cost {rebcost}, Operational Cost {opcost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
